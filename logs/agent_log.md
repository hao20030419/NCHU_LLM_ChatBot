# Agent 開發對話紀錄

## 2025-12-01 啟動專題
使用 ChatGPT 設計 Streamlit Chatbot 基礎架構。

【對話摘要】
- 決定專題為「文字生成聊天機器人」
- 建立 GitHub 專案結構
- 完成最小可執行 Streamlit chat 範例

## 2025-12-01 接入語言模型（GPT-2）

已完成：
- 安裝 transformers / torch
- 將假回應改為 HuggingFace GPT-2 模型
- 成功實現即時文字生成

問題：
- 初次載入模型較慢（需下載）
- GPT-2 中文能力有限，後續可改為其他模型

成果：
- 使用者輸入文字可即時生成回答

## 2025-12-01 更換模型為 Qwen2.5-1.5B

完成事項：
- 將原本 GPT2 改為 Qwen2.5-1.5B-Instruct
- 成功進行中文對話
- 建立上下文輸入拼接
- 模型可在本機 CPU 運作

觀察：
- 初次下載模型時間較久
- 中文生成效果明顯優於 GPT2

結論：
- 選擇 Qwen2.5-1.5B 作為專題模型

## 2025-12-01 新增角色與互動功能
- 加入 system prompt 設計
- 增加重設對話功能
- 提升對話一致性與教學風格

## 2025-12-01 更換模型為 Qwen2.5-0.5B

### 問題背景
原先嘗試於 Streamlit Cloud 部署 Qwen2.5-1.5B 模型時，因模型檔案體積較大，導致在免費雲端環境中發生記憶體不足與啟動失敗問題。

### 處理方式
經分析部署限制後，改採 Qwen2.5-0.5B-Instruct 作為替代模型，並進行以下調整：

- 更換模型名稱為 Qwen/Qwen2.5-0.5B-Instruct  
- 修正參數 `torch_dtype` 為 `dtype`，避免 API 警告  
- 重新 push 至 GitHub 觸發自動部署  
- 保留系統 prompt 與對話記憶機制

### 成果
- 成功於 Streamlit Cloud 完成部署  
- 模型可即時回覆中文內容  
- 回應品質穩定，適用於課程展示  
- 部署時間顯著縮短

### 結論
在雲端資源有限情境下，選擇較小尺寸之模型可有效降低部署門檻，同時維持可用之語言理解與生成能力。本次調整使專題順利完成部署，並符合展示與作業繳交需求。